PROJECT_NAME=inference_server

## URLS AND HOSTS
RABBIT_HOSTNAME=rabbit
RABBIT_PORT=5672
REVERSE-PROXY_HOSTNAME=traefik
JOB-CONSUMER_HOSTNAME=job-consumer

## RABBIT QUEUES
UNFINISHED_JOB_QUEUE=unfinished_job_queue
FINISHED_JOB_QUEUE=finished_job_queue

## ENVS
PYTHONUNBUFFERED=1
DOCKER_SOCKET=//var/run/docker.sock

## VOLUMES
DB_VOLUME=db_storage
DATA_VOLUME=data_storage
MODELS_VOLUME=models_storage
LOGS_VOLUME=logs_storage

## DIRS
DATA_DIR=/data
MODELS_DIR=/models
LOGGING_DIR=/logs



########## API ############

API_HOSTNAME=api
API_PORT=7000
API_URL=http://api:7000

## OUTPUT API
## An "output" output_zip associated with a task (the result of the task)
OUTPUT_PREFIX=/outputs
GET_OUTPUT_ZIP_BY_ID=/outputs/id/
GET_OUTPUT_ZIP_BY_UID=/outputs/uid/
POST_OUTPUT_ZIP_BY_UID=/outputs/uid/

## INPUT API
## An input is the input_zip file associated with a task.
## All posted inputs will arrive through the task api - see below
INPUT_PREFIX=/inputs
GET_INPUT_ZIP_BY_ID=/inputs/id/
GET_INPUT_ZIP_BY_UID=/inputs/uid/


## TASK API
## A task is the context with which to run a container on an input
TASK_PREFIX=/tasks
GET_TASKS=/tasks/
GET_TASK_BY_ID=/tasks/id/
GET_TASK_BY_UID=/tasks/uid/
POST_TASK=/task/

## MODEL API
## A task is the context with which to run a container on an input
MODEL_PREFIX=/models
GET_MODELS=/models/
GET_MODEL_BY_ID=/models/id/
GET_MODEL_BY_UID=/models/uid/
GET_MODEL_BY_HUMAN_READABLE_ID=/models/human_readable_id/

GET_MODEL_ZIP_BY_ID=/models/uid/zip/
POST_MODEL=/models/

NETWORK_NAME=inference_server_default

## JOB CONSUMER
PREFETCH_VALUE=1

######### PUBLIC API #########
## URLS AND HOSTS
PUBLIC_API_HOSTNAME=public-api
PUBLIC_API_PORT=8000

PUBLIC_API_URL=http://public-api:8000

## TASK API
## A task is the context with which to run a container on an input
PUBLIC_TASK_PREFIX=/api/tasks
PUBLIC_GET_OUTPUT_ZIP_BY_UID=/api/tasks/
PUBLIC_POST_TASK=/api/tasks

## MODEL API
## A task is the context with which to run a container on an input
PUBLIC_MODEL_PREFIX=/api/models
PUBLIC_GET_MODELS=/api/models
PUBLIC_POST_MODEL=/api/models

PROXY_URL=localhost
HTTPS_ON=true


#### IMAGES ####
VOLUME_SENDER_DOCKER_TAG=mathiser/inference_server:volume_sender
RABBIT_DOCKER_TAG=rabbitmq:3.9.17
BUSYBOX_DOCKER_TAG=busybox:1.35